# Assignment Feedback: Week 04 Dimensionality Reduction

**Student:** whoettl-g
**Raw Score:** 46/50 (92.0%)
**Course Points Earned:** 92.0

---

## Problem Breakdown

### Exercise 2 (9/10 = 90.0%)

**Part ex1-part1** (ex1-part1.code): 4/4 points

_Feedback:_ Good job: you run t-SNE to 2D and color by labels, achieving the visualization goal. For clarity, consider using the MNIST vars from above (X_mnist_train/y_mnist_train), add cmap, colorbar, title, and a small point size.

**Part ex1-part2** (ex1-part2.code): 2/3 points

_Feedback:_ Good attempt: you used t-SNE features with KNN and reported accuracy. However, you fit t-SNE separately on train and test, producing incompatible embeddings and invalid accuracy. Instead, embed once then split, or split first then embed together. Printing accuracy is fine.

**Part ex1-part3** (ex1-part3.code): 3/3 points

_Feedback:_ Good job: you used UMAP, fit on train and transformed test, then trained KNN and computed accuracy. This matches the task and is consistent with prior work assumptions. Choice of 50 components and k=3 is reasonable.

---

### Exercise 4 (17/20 = 85.0%)

**Part ex2-part1** (ex2-part1.code): 7/7 points

_Feedback:_ Good job. You applied PCA (4 components), trained kNN on transformed data, evaluated accuracy, and provided an informative 3D scatter visualization using PC1-3 with point size from PC4. Approach is correct and complete for the task.

**Part ex2-part2** (ex2-part2.code): 7/7 points

_Feedback:_ Good use of UMAP: you fit/transform train data, visualized 3D + size by 4th comp, and built a KNN on UMAP features with train/test split and accuracy. Approach matches your prior PCA workflow. Solid implementation.

**Part ex2-part3** (ex2-part3.answer): 3/6 points

_Feedback:_ You compared PCA and UMAP results, but didn’t explore parameters (e.g., neighbors) and conflated 3D UMAP visualization with accuracy (you reported 58.5% for 3D though accuracy was computed at 50D). To reach full credit, note UMAP often excels in low dims with low k and show param

---

### Exercise 1 (20/20 = 100.0%)

**Part pipeline-part1** (pipeline-part1.code): 4/4 points

_Feedback:_ Good job: PCA to 2D and scatter colored by class meets the goal. For clarity, consider adding a title, colorbar, and plt.show(), and ensure you’re using the intended train data (e.g., X_mnist_train, y_mnist_train) if required by the notebook.

**Part pipeline-part2** (pipeline-part2.code): 4/4 points

_Feedback:_ Correct scree plot: you refit PCA on full data and plotted the first 40 components with percent variance. Consider adding axis labels/title for clarity, but the core requirement is met.

**Part pipeline-part3** (pipeline-part3.code): 4/4 points

_Feedback:_ Correct approach. You compute the cumulative explained variance and find the smallest number of components reaching 95% using argmax + 1. This correctly uses the previously fitted pca from prior work. Well done.

**Part pipeline-part4** (pipeline-part4.code): 4/4 points

_Feedback:_ Good job. You used n_components_95 from Step 4, projected X_mnist_train, inverse-transformed the first digit, and visualized it. This correctly shows the digit in the reduced-dimensionality reconstruction.

**Part pipeline-part5** (pipeline-part5.code): 4/4 points

_Feedback:_ Good job. You applied PCA preserving 80% variance, transformed train/test consistently, and compared KNN accuracy with and without PCA. Clear, correct, and meets the objective. No issues detected.

---

## Additional Information

This feedback was automatically generated by the autograder.

**Generated:** 2025-10-28 19:52:00 UTC

If you have questions about your grade, please reach out to the instructor.